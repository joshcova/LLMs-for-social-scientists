{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9v3KLqatD7dEcOFG3Zwsj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshcova/LLMs-for-social-scientists/blob/main/code/ChatGPT_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install retry"
      ],
      "metadata": {
        "id": "1Z1iN90qMMui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J1QxZtM8J0tx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "import requests\n",
        "import re\n",
        "from typing import List, Dict\n",
        "from retry.api import retry_call\n",
        "from tqdm.auto import tqdm\n",
        "import time\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up an API key"
      ],
      "metadata": {
        "id": "jqDWb_r8Oy-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WARNING: Use this method only for testing and personal projects\n",
        "# Set up your API key (https://platform.openai.com/docs/quickstart)\n",
        "\n",
        "client = OpenAI(api_key=os.environ.get(\"\"))"
      ],
      "metadata": {
        "id": "dnpFq_cVMW-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading our classification sample"
      ],
      "metadata": {
        "id": "gw4c1q0YOx_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/joshcova/LLMs-for-social-scientists/main/data/uk_media_2.csv\")\n",
        "\n",
        "df = df[[\"majortopic\",\"text\"]]\n",
        "df = df.rename(columns={\"majortopic\":\"label\"})\n",
        "\n",
        "df = df.groupby(\"label\").sample(n=50, random_state=1)"
      ],
      "metadata": {
        "id": "em2YSB5ONh7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompting the LLM"
      ],
      "metadata": {
        "id": "gyTrXjd1NoUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAIError\n",
        "\n",
        "def send_prompt_with_context(model: str,\n",
        "                             messages: List[Dict],\n",
        "                             max_tokens: int = 0) -> Dict[str, str]:\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.0,\n",
        "        seed=42,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "    pass\n",
        "\n",
        "categories = [\"0: Law & Crime\", \"1: Macroeconomics\", \"2: Unclear\"]\n",
        "\n",
        "definitions = \"\"\"\n",
        "0: The newspaper headline concerns the topic Law & Crime. \\\\\n",
        "1: The newspaper headline concerns the topic Macroeconomics. \\\\\n",
        "2: It is unclear whether the newspaper headline concerns the topics Law & Crime or Macroeconomics.\n",
        "\"\"\"\n",
        "\n",
        "def predict_sentiment(review: str, model: str) -> Dict[str, str]:\n",
        "                system_msg = f\"\"\"\n",
        "                    You are a skilled research assistant who will help to classify newspaper headlines. \\\\\n",
        "                    Classify the following text into one of the given categories: {categories}\\n{definitions} \\\\\n",
        "                    Only include the number of the selected category in your response and no further text.\"\n",
        "                    \"\"\"\n",
        "                messages = [\n",
        "                    {\"role\": \"system\", \"content\": system_msg},\n",
        "                    {\"role\": \"user\", \"content\": review}\n",
        "                ]\n",
        "                return send_prompt_with_context(model, messages)"
      ],
      "metadata": {
        "id": "WPOu4J4RNpT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sending out the texts"
      ],
      "metadata": {
        "id": "Z87FSuUWO63C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['GPT_4o'] = df['text'].progress_apply(lambda x: predict_sentiment(x, model='gpt-4o-2024-11-20'))"
      ],
      "metadata": {
        "id": "od5KZEXXNtQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reviewing a subset of annotated sentences"
      ],
      "metadata": {
        "id": "qX1RLFaHO9bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[['text', 'GPT_4o']])"
      ],
      "metadata": {
        "id": "KO6sBrNZNw4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"GPT_4o\"] = df[\"GPT_4o\"].astype(int)"
      ],
      "metadata": {
        "id": "Zos0FqLBNyxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation"
      ],
      "metadata": {
        "id": "QuTFBny8PBVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the second df with any model of your choice\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, balanced_accuracy_score\n",
        "\n",
        "metrics = {\n",
        "    \"Metric\": [\"F1 Score (macro)\", \"F1 Score (micro)\", \"Balanced Accuracy\"],\n",
        "    \"Value\": [\n",
        "        f1_score(df[\"label\"], df[\"GPT_4o\"], average='macro'),\n",
        "        f1_score(df[\"label\"], df[\"GPT_4o\"], average='micro'),\n",
        "        balanced_accuracy_score(df[\"label\"], df[\"GPT_4o\"])\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Convert the dictionary into a DataFrame for nice tabular representation\n",
        "results_df = pd.DataFrame(metrics)\n",
        "\n",
        "# Display the results table\n",
        "results_df"
      ],
      "metadata": {
        "id": "rNXr4kmxMtKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "<style scoped>\n",
        "    .dataframe tbody tr th:only-of-type {\n",
        "        vertical-align: middle;\n",
        "    }\n",
        "\n",
        "    .dataframe tbody tr th {\n",
        "        vertical-align: top;\n",
        "    }\n",
        "\n",
        "    .dataframe thead th {\n",
        "        text-align: right;\n",
        "    }\n",
        "</style>\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Metric</th>\n",
        "      <th>Value</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>F1 Score (macro)</td>\n",
        "      <td>0.601442</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>F1 Score (micro)</td>\n",
        "      <td>0.830000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>Balanced Accuracy</td>\n",
        "      <td>0.830000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
      ],
      "metadata": {
        "id": "_1HHBGOyMyDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating metrics per class\n",
        "# Replace the second df with any model of your choice\n",
        "precision_per_class = precision_score(df[\"label\"], df[\"GPT_4o\"], average=None, labels=[0,1,2])\n",
        "recall_per_class = recall_score(df[\"label\"], df[\"GPT_4o\"], average=None, labels=[0,1,2])\n",
        "f1_per_class = f1_score(df[\"label\"], df[\"GPT_4o\"], average=None, labels=[0,1,2])\n",
        "\n",
        "# Since accuracy is a global metric (not class-specific), we will not recalculate it here.\n",
        "\n",
        "# Create a DataFrame from the metrics\n",
        "metrics_per_class_df = pd.DataFrame({\n",
        "    \"Class\": [0, 1, 2],\n",
        "    \"Precision\": precision_per_class,\n",
        "    \"Recall\": recall_per_class,\n",
        "    \"F1 Score\": f1_per_class\n",
        "})\n",
        "\n",
        "# Display the results table\n",
        "metrics_per_class_df"
      ],
      "metadata": {
        "id": "OGRYFi9HMxI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "<style scoped>\n",
        "    .dataframe tbody tr th:only-of-type {\n",
        "        vertical-align: middle;\n",
        "    }\n",
        "\n",
        "    .dataframe tbody tr th {\n",
        "        vertical-align: top;\n",
        "    }\n",
        "\n",
        "    .dataframe thead th {\n",
        "        text-align: right;\n",
        "    }\n",
        "</style>\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Class</th>\n",
        "      <th>Precision</th>\n",
        "      <th>Recall</th>\n",
        "      <th>F1 Score</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>0</td>\n",
        "      <td>0.976744</td>\n",
        "      <td>0.84</td>\n",
        "      <td>0.903226</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>1</td>\n",
        "      <td>1.000000</td>\n",
        "      <td>0.82</td>\n",
        "      <td>0.901099</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>2</td>\n",
        "      <td>0.000000</td>\n",
        "      <td>0.00</td>\n",
        "      <td>0.000000</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
      ],
      "metadata": {
        "id": "mYPl2WU5N4kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For future reference, it is advisable to save the resulting dataframe locally\n",
        "\n",
        "df.to_csv(\"uk_media_2_results.csv\")"
      ],
      "metadata": {
        "id": "Wc40tRG2a_DJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Central bank independence corpus\n",
        "\n",
        "Let us see how well ChatGPT performs on our other dataset on parliamentary interventions on central bank independence.  "
      ],
      "metadata": {
        "id": "mL4Rj3ICPPhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/joshcova/LLMs-for-social-scientists/main/data/uk_cbi_sample.csv\")"
      ],
      "metadata": {
        "id": "m1PUp_-majBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if 'Sentences' column exists\n",
        "if 'sents' in df.columns:\n",
        "    # Extract texts from the 'Sentences' column\n",
        "    texts = df['sents'].tolist()\n",
        "\n",
        "    # Example: Print the first few texts to verify\n",
        "    for text in texts[:5]:  # Adjust the number to print as needed\n",
        "        print(text)\n",
        "else:\n",
        "    print(\"The 'sents' column was not found in the CSV file.\")"
      ],
      "metadata": {
        "id": "sJJBSDx1awAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from openai import OpenAIError\n",
        "\n",
        "def send_prompt_with_context(model: str,\n",
        "                             messages: List[Dict],\n",
        "                             max_tokens: int = 0) -> Dict[str, str]:\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.0,\n",
        "        seed=42,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "    pass\n",
        "\n",
        "categories = [\"0: anti-independence\", \"1: pro-independence\", \"2: unrelated\"]\n",
        "\n",
        "definitions = \"\"\"\n",
        "0: The statement expresses opposition for central bank independence. \\\\\n",
        "1: The statement expresses support for central bank independence. \\\\\n",
        "2: The statemnent does not contain a clear expression in support or opposition to central bank independence.\n",
        "\"\"\"\n",
        "\n",
        "def predict_sentiment(review: str, model: str) -> Dict[str, str]:\n",
        "                system_msg = f\"\"\"\n",
        "                    You are a skilled research assistant who will help to classify parliamentary interventions on central bank independence. \\\\\n",
        "                    Central bank independence can relate to formal independence (the legal provisions that guarantee the central bank's autonomy, such as its mandate, its organizational structure, and the procedures for appointing its leaders), and actual independence (taking into account factors such as its political and institutional environment, its relationship with the government, and the level of transparency and accountability in its operations). \\\\\n",
        "                    Classify the following text into one of the given categories: {categories}\\n{definitions} \\\\\n",
        "                    Only include the number of the selected category in your response and no further text.\"\n",
        "                    \"\"\"\n",
        "                messages = [\n",
        "                    {\"role\": \"system\", \"content\": system_msg},\n",
        "                    {\"role\": \"user\", \"content\": review}\n",
        "                ]\n",
        "                return send_prompt_with_context(model, messages)\n"
      ],
      "metadata": {
        "id": "llR6beiTQCkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['GPT_4o'] = df['sents'].progress_apply(lambda x: predict_sentiment(x, model='gpt-4o-2024-11-20'))"
      ],
      "metadata": {
        "id": "C-bjqnaYQDOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, balanced_accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "Fvoky_x_XgT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save a separate data frame for validation purposes\n",
        "\n",
        "df_validate = pd.DataFrame(df)"
      ],
      "metadata": {
        "id": "lCfw2SejXav5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the data to ensure that the data types match (this is important for the subsequent step)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df_validate[\"GPT_4o_encoded\"] = label_encoder.fit_transform(df_validate[\"GPT_4o\"])"
      ],
      "metadata": {
        "id": "Ao4F2598Xig-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_encoded = df_validate[\"results_number\"]\n"
      ],
      "metadata": {
        "id": "lwsly4J0Xqso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = {\n",
        "    \"Metric\": [\"F1 Score (macro)\", \"F1 Score (micro)\", \"Balanced Accuracy\"],\n",
        "    \"Value\": [\n",
        "        f1_score(category_encoded, df_validate[\"GPT_4o_encoded\"], average='macro'),\n",
        "        f1_score(category_encoded, df_validate[\"GPT_4o_encoded\"], average='micro'),\n",
        "        balanced_accuracy_score(category_encoded, df_validate[\"GPT_4o_encoded\"])\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Convert the dictionary into a DataFrame for nice tabular representation\n",
        "results_df = pd.DataFrame(metrics)\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "bReBXoQiXtBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Metric</th>\n",
        "      <th>Value</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>F1 Score (macro)</td>\n",
        "      <td>0.610818</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>F1 Score (micro)</td>\n",
        "      <td>0.713333</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>Balanced Accuracy</td>\n",
        "      <td>0.710517</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "RJ9eFgIoYiYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating metrics per class\n",
        "# Replace the second df with any model of your choice\n",
        "precision_per_class = precision_score(category_encoded, df_validate[\"GPT_4o_encoded\"], average=None, labels=[0,1,2])\n",
        "recall_per_class = recall_score(category_encoded, df_validate[\"GPT_4o_encoded\"], average=None, labels=[0,1,2])\n",
        "f1_per_class = f1_score(category_encoded, df_validate[\"GPT_4o_encoded\"], average=None, labels=[0,1,2])\n",
        "\n",
        "# Since accuracy is a global metric (not class-specific), we will not recalculate it here.\n",
        "\n",
        "# Create a DataFrame from the metrics\n",
        "metrics_per_class_df = pd.DataFrame({\n",
        "    \"Class\": [0, 1, 2],\n",
        "    \"Precision\": precision_per_class,\n",
        "    \"Recall\": recall_per_class,\n",
        "    \"F1 Score\": f1_per_class\n",
        "})\n",
        "\n",
        "# Display the results table\n",
        "metrics_per_class_df"
      ],
      "metadata": {
        "id": "fIlj2S68YQbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "<style scoped>\n",
        "    .dataframe tbody tr th:only-of-type {\n",
        "        vertical-align: middle;\n",
        "    }\n",
        "\n",
        "    .dataframe tbody tr th {\n",
        "        vertical-align: top;\n",
        "    }\n",
        "\n",
        "    .dataframe thead th {\n",
        "        text-align: right;\n",
        "    }\n",
        "</style>\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Class</th>\n",
        "      <th>Precision</th>\n",
        "      <th>Recall</th>\n",
        "      <th>F1 Score</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>0</td>\n",
        "      <td>0.250000</td>\n",
        "      <td>0.800000</td>\n",
        "      <td>0.380952</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>1</td>\n",
        "      <td>0.848837</td>\n",
        "      <td>0.858824</td>\n",
        "      <td>0.853801</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>2</td>\n",
        "      <td>0.812500</td>\n",
        "      <td>0.472727</td>\n",
        "      <td>0.597701</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
      ],
      "metadata": {
        "id": "na_6ijvDYbVX"
      }
    }
  ]
}